{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad48582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are going to import numpy and opencv again\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c11b6930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to load the files here\n",
    "with_mask = np.load('with_mask.npy')\n",
    "without_mask = np.load('without_mask.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5b55453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 50, 50, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets see the shape of these two files\n",
    "with_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "258008eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 50, 50, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aaa31102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can convert this 4d data to 2d using reshapr func\n",
    "with_mask = with_mask.reshape(200, 50*50*3)\n",
    "without_mask = without_mask.reshape(200, 50*50*3) #now they will have 200 img and 7500 columns hence converted to 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c905909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 7500)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_mask.shape\n",
    "without_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "24c98674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255,   0, 255, ..., 255,   0, 255],\n",
       "       [255,   0, 255, ..., 255,   0, 255],\n",
       "       [255,   0, 255, ..., 243,   1, 243],\n",
       "       ...,\n",
       "       [255,   0, 255, ..., 252,   3, 252],\n",
       "       [255,   0, 255, ..., 253,   2, 253],\n",
       "       [255,   0, 255, ..., 254,   1, 254]], dtype=uint8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we have data and we are gng to combine it first 200 rows is with mask and next 200 rows is without mask\n",
    "X = np.r_[with_mask, without_mask] #we are appending without mask after with mask hence our training data is prepared , r_ is used in numpy to concatenate the rows\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ebcca485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 7500)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "15202ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we are going to label with mask as 0 and without mask 1\n",
    "labels = np.zeros(X.shape[0])\n",
    "#we have totally 400 zeros for 400 images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "831ab911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we have to make first 200 as 0 and next 200 as 1.0\n",
    "labels[200:] = 1.0\n",
    "#so first 200 with 0 will point with mask data and next 200 will point without mask data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "98178256",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {0 : 'with MASK', 1 : 'without MASK '}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f4512ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so, if the op is 0 we are wearing mask and if not zero we are not wearing mask\n",
    "#so now our data is prepared that is we have two categories with mask and without mask\n",
    "#lets perform ml on it\n",
    "#ml is nothing but combo of maths and programming, ultimate goal of it is we need a machine that learns from experience\n",
    "#it is divided into 2 parts supervised(regression - continuous data and classification - for categorical data) and unsupervised some other categories are semi supervised and reinforcement learning\n",
    "#our problem is categorical or classification so we can perform logistic regression , svm- support vector machines, Decision tree etc..\n",
    "#there are lots of algorithms in classification it is the algorithm which gives accuracy\n",
    "#here we are going to use the py lib \"sklearn\" - scikit-learn it is the bundle of ml libraries it will already have the algorithms we can use the one which is good for us\n",
    "#we can do classification,regression,preprocessing,model selection,dimensionality reduction etc,.. acc to our need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cbe25c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC #SVM - SUPPORT VECTOR MACHINE AND SVC - SUPPORT VECTOR CLASSIFICATION SINCE IT IS CATEGORICAL DATA\n",
    "#nowwe import another one for accuracy check\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b2960079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finallly we import one more to split our data set\n",
    "from sklearn.model_selection import train_test_split #this helps us to divide our data into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4039d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training part will helps us in training the model and testing part will be use to check the predictions, accuracy of trained model\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, labels, test_size = 0.25) # we are passing our data and mentioning that 25% of the data is for training model\n",
    "#this returns x_tain and y_train and x_test and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "902356b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 7500)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets look into the dimensions\n",
    "x_train.shape #here only 300 will be used for training because remaining will be used for testing i.e is 100\n",
    "#but we have 7500 columns if we have lots of columns our ml algorithm is going to slow down "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e65fdb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so there is a technique known as dimensionality reduction in the ml for solving the above mentioned column problem\n",
    "#basically the purpose of using dimensionality reduction is to reduce he dimension thereby increasing the algorithm speed\n",
    "#so to perform this we r gng to import a package known as decomposition\n",
    "#PCA - principle component analysis\n",
    "from sklearn.decomposition import PCA #this will help us to reduce the dimensions of our data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "51a7ecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 3) #we have to pass the number of comp here we need 3d so passed so we are reducing it from 7500 to 3\n",
    "#it has fit-transform method and we have to pass x_train into it\n",
    "x_train = pca.fit_transform(x_train) #so now our data will be converted into 3 columns\n",
    "#the mathematics used here is eigen values and eigen vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a4c30f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now finally we have training data with reduced dimensions\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4a2630ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, labels, test_size = 0.30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5eacb4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finnaly its time to apply ml \n",
    "svm = SVC()\n",
    "svm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7474535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now there is a predict method to do the predictions\n",
    "#we have transform test data also is error appears using pca.transform\n",
    "y_pred = svm.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "22180395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can also check the accuracies by comparing actually test dat with predicitons\n",
    "accuracy_score(y_test, y_pred) #two arg are actual test data and prediction data\n",
    "#incase of overfitting we get the accuracy of 100% that means it is trained so perfectly on a particular data so we have accuracy as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "48b3b629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are coping the test-train-split code above svm cell , bcoz we r again shuffling the data so we r shuffling the data again but it is not necessary that it is going to make lot of channges but it will reduce the data from overfitting\n",
    "#so 100 percent accuracy is not good bcoz that means overfitting taht is trained on a specific data, so we keep on shuffling our data so that our accuarcy changes and model is trained acc to different data\n",
    "#we should also copy the haar_data code since we have the cascade classifier there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b197456e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "with MASK\n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "with MASK\n",
      "without MASK \n",
      "without MASK \n",
      "with MASK\n",
      "without MASK \n",
      "with MASK\n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "with MASK\n",
      "without MASK \n",
      "without MASK \n",
      "with MASK\n",
      "without MASK \n",
      "without MASK \n",
      "with MASK\n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n",
      "with MASK\n",
      "without MASK \n",
      "without MASK \n",
      "without MASK \n"
     ]
    }
   ],
   "source": [
    "#so 97.5 accuracy is good one, now lets test the model so lets copy the code for capturing the data\n",
    "#now we know to detect the faces next we have to know whether they are wearing mask or not\n",
    "#so we have to collect data now we have to start the camera\n",
    "#now we have to load the classifier file \n",
    "haar_data = cv2.CascadeClassifier('E:\\py\\projects ML\\mask detection\\haarcascade_frontalface_default.xml') #this code helps to load the file and we have to pass the file name as arg\n",
    "capture = cv2.VideoCapture(0) #here 0 is the default value for our camera #1 for external camera if we have installed and we put this data in a var\n",
    "data = []\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "while True :\n",
    "    flag, img = capture.read() #read will return two var one is flag and another one is img #this flag var will be either true or false it will give true if ur camera is working false if camera id not working\n",
    "    if flag:\n",
    "        faces = haar_data.detectMultiScale(img) #this is if camera is working we are gng to detect the face of the img\n",
    "        for x,y,w,h in faces:\n",
    "            cv2.rectangle(img, (x,y), (x+w ,y+h), (255,0,255), 4)\n",
    "            face = img[y:y+h, x:x+w, :]# here our image is 3d so first we have row, column and final : is for color code sinc our image is 3d using this we can fetch the face\n",
    "            #the faces will be of different dimensions so we are going to resize all my faces into same dimension\n",
    "            face = cv2.resize(face, (50,50))\n",
    "            face = face.reshape(1,-1) #this is because we have to fit the shape into our frame since we detect it from live capture\n",
    "            #face = pca.transform(face)#we r applying the pca transform directly here so our data will be reduced to the 3d\n",
    "            pred = svm.predict(face)#this will return either 1 or 0 according to mask so above we can create a variable to say mask or not\n",
    "            n = names[int(pred)] #this will give wether we have mask or not\n",
    "            cv2.putText(img, n, (x,y), font, 1, (244,250,250), 2) #by this method we are going to write text, img, n is with or without mask, font , 1 is default 16 pixel, color between 0 to 255, 4 is to make it bold\n",
    "            print(n) #this will print n\n",
    "            #now we have to store the data of this face we r taking a variable called data and going to append there\n",
    "            #print(len(data))\n",
    "            #if len(data) < 400: #here we r considering only 400 images \n",
    "             #   data.append(face) we are commenting this bcoz now we are going to test so we r not going to store data so this part doesnt require\n",
    "        cv2.imshow('result', img)\n",
    "        if cv2.waitKey(2) == 27 : #or len(data) >= 200: we r commenting this condition since we r not storing data#so the loop will break if we press esc or len of data crosses 200\n",
    "            break #this is copied from above code that is if there is face it will draw a rectangle\n",
    "capture.release() #this is used to release the camera that we are holiding\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccefbc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
